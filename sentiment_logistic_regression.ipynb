{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-logistic-regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/dIWBH2y2P39yS5zns5rN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tejas2008/Sentiment-analysis/blob/master/sentiment_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRgeFA_qzBTi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2312ae4b-c338-4ed5-f91b-8af6d925e8e4"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "from nltk.stem import PorterStemmer "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keRQV-lx0Phz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "f897c1b3-df2a-472c-edc6-3dc3ccfd0b58"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.corpus import twitter_samples \n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqmjgzaS0ZZo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmssnySR0dai",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "34964989-0c70-439d-8ecd-a705a7c21279"
      },
      "source": [
        "len(positive_tweets)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9z3p1Bl1Bk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_pos = positive_tweets[4000:]\n",
        "train_pos = positive_tweets[:4000]\n",
        "test_neg = negative_tweets[4000:]\n",
        "train_neg = negative_tweets[:4000]\n",
        "train_x = train_pos + train_neg \n",
        "test_x = test_pos + test_neg"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cX9Vm1_J22L0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7dcbf737-daa1-4975-bd52-85e1200a9104"
      },
      "source": [
        "len(train_x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkddCO0l3DQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
        "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx7yf5v14Pgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "6fbf45cb-70d5-4a8e-b394-889e96844d3e"
      },
      "source": [
        "train_y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.],\n",
              "       ...,\n",
              "       [0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mOiiLTm4RGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stemmer = PorterStemmer()\n",
        "def preprocess(tweet):\n",
        "  punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*'''\n",
        "  tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
        "  tweet = re.sub(r'#', '', tweet)\n",
        "  tokn_word = tknzr.tokenize(tweet)\n",
        "  stp_words = set(stopwords.words('english')) \n",
        "  out = []\n",
        "  for i in tokn_word:\n",
        "    if i not in stp_words and i not in punc:\n",
        "      j = stemmer.stem(i)\n",
        "      out.append(j)\n",
        "  return out\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY0l1Lkg7z1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "63f3e519-5a35-4d6a-b443-09d1f641cf47"
      },
      "source": [
        "for i in range(len(train_x)):\n",
        "  train_x[i] = preprocess(train_x[i])\n",
        "print(train_x[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['followfriday', 'top', 'engag', 'member', 'commun', 'week', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHgKM-rTIq4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fre = {}\n",
        "def frequency(l):\n",
        "  freqs = {}\n",
        "  for i in range(4000):\n",
        "    for word in l[i]:\n",
        "      if (word,1) in freqs:\n",
        "        freqs[(word,1)] += 1\n",
        "      else:\n",
        "        freqs[(word,1)] = 1 \n",
        "  for i in range(4000,8000):\n",
        "    for word in l[i]:\n",
        "      if (word,0) in freqs:\n",
        "        freqs[(word,0)] += 1\n",
        "      else:\n",
        "        freqs[(word,0)] = 1 \n",
        "  return freqs\n",
        "fre = frequency(train_x)\n",
        "# print(fre)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1mTQYLKmmIC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "79cef8fc-50ea-4c26-81df-e0ef8dd8fff9"
      },
      "source": [
        "def vec_for_model(fre,l):\n",
        "  x = []\n",
        "  for i in range(len(l)):\n",
        "    temp = []\n",
        "    temp.append(1)\n",
        "    pos_count = 0\n",
        "    neg_count = 0\n",
        "    for word in l[i]:\n",
        "      pos_count += fre.get((word,1),0)\n",
        "      neg_count += fre.get((word,0),0)\n",
        "    temp.append(pos_count)\n",
        "    temp.append(neg_count)\n",
        "    x.append(temp)\n",
        "  return x\n",
        "X = np.array(vec_for_model(fre,train_x),dtype=np.float128)\n",
        "print(X[:10])\n",
        "print(X.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.000e+00 3.020e+03 6.100e+01]\n",
            " [1.000e+00 3.591e+03 4.620e+02]\n",
            " [1.000e+00 3.113e+03 2.190e+02]\n",
            " [1.000e+00 2.862e+03 4.000e+00]\n",
            " [1.000e+00 3.116e+03 2.240e+02]\n",
            " [1.000e+00 2.986e+03 1.570e+02]\n",
            " [1.000e+00 4.064e+03 6.120e+02]\n",
            " [1.000e+00 3.205e+03 3.290e+02]\n",
            " [1.000e+00 6.200e+02 1.830e+02]\n",
            " [1.000e+00 2.670e+02 1.170e+02]]\n",
            "(8000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS36Q2jg1M5q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "076b8496-2de4-4aba-a827-4f99b75f6b3b"
      },
      "source": [
        "def gradient(x,y,no_itr):\n",
        "  eta = 0.001\n",
        "  wt = np.zeros((3, 1))\n",
        "  for i in range(no_itr):\n",
        "    z = np.dot(x,wt)\n",
        "    h = 1/(1 + np.exp(-z))\n",
        "    j=(-1/len(x))*(np.dot(y.T,np.log(h))+np.dot((1-𝐲).T,np.log(1-𝐡)))\n",
        "    wt=wt-(eta/len(x))*np.dot(𝐱.T,(𝐡-𝐲))\n",
        "  return j,wt\n",
        "\n",
        "cost,weights = gradient(X,train_y,1000)\n",
        "print(cost)\n",
        "print(weights)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in log\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[nan]]\n",
            "[[-0.00195366]\n",
            " [ 1.31689719]\n",
            " [-0.89869581]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvxArsEi5iU8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c3cb590-5ba9-4f0b-8ec6-fb203cd1739d"
      },
      "source": [
        "def pre_sentiment(tweet,weights,fre):\n",
        "  l = preprocess(tweet)\n",
        "  l1 = []\n",
        "  l1.append(l)\n",
        "  x = np.array(vec_for_model(fre,l1),dtype=np.float128)\n",
        "  z = np.dot(x,weights)\n",
        "  # print(x)\n",
        "  # print(z)\n",
        "  y_pr = 1/(1+np.exp(-z))\n",
        "  # print(y_pr)\n",
        "  if y_pr >= 0.5 :\n",
        "    return 'Positive'\n",
        "  else:\n",
        "    return 'Negative'\n",
        "\n",
        "pre_sentiment('it is a great movie',weights,fre)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Positive'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVs76i65gSsi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGe8W1nd--wZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}