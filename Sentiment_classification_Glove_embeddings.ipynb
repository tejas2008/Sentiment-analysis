{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mip_DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0ZgZkz5EAbg",
        "outputId": "a35fb321-67eb-4ae7-83b7-6e5cacf26fb3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import re\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "tknzr = TweetTokenizer(strip_handles=True)\n",
        "from nltk.stem import PorterStemmer\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from nltk.corpus import stopwords \n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4fgEYRoEKRe",
        "outputId": "79da4190-d991-456b-bd92-17c09aebeac7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/\n",
        "%cd MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n",
            "/gdrive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "uh4B43xDEMIW",
        "outputId": "9505a7b2-cfae-4413-ddb4-65d466926007"
      },
      "source": [
        "reviews = pd.read_excel('restaurant_reviews_sentiment_dataset.xlsx')\n",
        "reviews.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Now I am getting angry and I want my damn pho.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The potatoes were like rubber and you could te...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The fries were great too.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>A great touch.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1\n",
              "5     Now I am getting angry and I want my damn pho.      0\n",
              "6              Honeslty it didn't taste THAT fresh.)      0\n",
              "7  The potatoes were like rubber and you could te...      0\n",
              "8                          The fries were great too.      1\n",
              "9                                     A great touch.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gZMCug3NRVo"
      },
      "source": [
        "X = reviews['Review'].to_numpy()\n",
        "y = reviews['Liked'].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQorWxAIQQj0"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIHcpxYITBKJ",
        "outputId": "17545c85-111e-4e8f-a19f-bc01159292c7"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-22 17:23:52--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-03-22 17:23:52--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-03-22 17:23:52--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.3’\n",
            "\n",
            "glove.6B.zip.3      100%[===================>] 822.24M  5.20MB/s    in 2m 39s  \n",
            "\n",
            "2021-03-22 17:26:32 (5.16 MB/s) - ‘glove.6B.zip.3’ saved [862182613/862182613]\n",
            "\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTnl2FqIaqcm"
      },
      "source": [
        "Another Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ceEsqZlZJOF"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input ,SimpleRNN\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "import string\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soRtFjRnayvX"
      },
      "source": [
        "reviews['Review'] = reviews['Review'].str.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggTdsKJFa-YV"
      },
      "source": [
        "stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \n",
        "             \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\",\n",
        "             \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \n",
        "             \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\",\n",
        "             \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\",\n",
        "             \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \n",
        "             \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\",\n",
        "             \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\",\n",
        "             \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\",\n",
        "             \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\",\n",
        "             \"your\", \"yours\", \"yourself\", \"yourselves\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "EJ86t7MQbAvB",
        "outputId": "a77a4773-e51c-43ec-9038-4cce8e535874"
      },
      "source": [
        "def remove_stopwords(data):\n",
        "  reviews['review without stopwords'] = reviews['Review'].apply(lambda x : ' '.join([word for word in x.split() if word not in (stopwords)]))\n",
        "  return reviews\n",
        "\n",
        "def remove_tags(string):\n",
        "    result = re.sub('<.*?>','',string)\n",
        "    return result\n",
        "    \n",
        "data_without_stopwords = remove_stopwords(reviews)\n",
        "data_without_stopwords['clean_review']= data_without_stopwords['review without stopwords'].apply(lambda cw : remove_tags(cw))\n",
        "data_without_stopwords['clean_review'] = data_without_stopwords['clean_review'].str.replace('[{}]'.format(string.punctuation), ' ')\n",
        "data_without_stopwords[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "      <th>review without stopwords</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow... loved this place.</td>\n",
              "      <td>1</td>\n",
              "      <td>wow... loved place.</td>\n",
              "      <td>wow    loved place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crust is not good.</td>\n",
              "      <td>0</td>\n",
              "      <td>crust not good.</td>\n",
              "      <td>crust not good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "      <td>not tasty texture just nasty.</td>\n",
              "      <td>not tasty texture just nasty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stopped by during the late may bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "      <td>stopped late may bank holiday off rick steve r...</td>\n",
              "      <td>stopped late may bank holiday off rick steve r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>selection menu great prices.</td>\n",
              "      <td>selection menu great prices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>now i am getting angry and i want my damn pho.</td>\n",
              "      <td>0</td>\n",
              "      <td>now getting angry want damn pho.</td>\n",
              "      <td>now getting angry want damn pho</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>honeslty it didn't taste that fresh.)</td>\n",
              "      <td>0</td>\n",
              "      <td>honeslty didn't taste fresh.)</td>\n",
              "      <td>honeslty didn t taste fresh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>the potatoes were like rubber and you could te...</td>\n",
              "      <td>0</td>\n",
              "      <td>potatoes like rubber tell made ahead time kept...</td>\n",
              "      <td>potatoes like rubber tell made ahead time kept...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>the fries were great too.</td>\n",
              "      <td>1</td>\n",
              "      <td>fries great too.</td>\n",
              "      <td>fries great too</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a great touch.</td>\n",
              "      <td>1</td>\n",
              "      <td>great touch.</td>\n",
              "      <td>great touch</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  ...                                       clean_review\n",
              "0                           wow... loved this place.  ...                                wow    loved place \n",
              "1                                 crust is not good.  ...                                    crust not good \n",
              "2          not tasty and the texture was just nasty.  ...                      not tasty texture just nasty \n",
              "3  stopped by during the late may bank holiday of...  ...  stopped late may bank holiday off rick steve r...\n",
              "4  the selection on the menu was great and so wer...  ...                       selection menu great prices \n",
              "5     now i am getting angry and i want my damn pho.  ...                   now getting angry want damn pho \n",
              "6              honeslty it didn't taste that fresh.)  ...                      honeslty didn t taste fresh  \n",
              "7  the potatoes were like rubber and you could te...  ...  potatoes like rubber tell made ahead time kept...\n",
              "8                          the fries were great too.  ...                                   fries great too \n",
              "9                                     a great touch.  ...                                       great touch \n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKO6KJ_qb1FE"
      },
      "source": [
        "reviews = data_without_stopwords['clean_review']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyjxvsAWbP6m"
      },
      "source": [
        "reviews_list = []\n",
        "for i in range(len(reviews)):\n",
        "  reviews_list.append(reviews[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spAAa7B9b32-"
      },
      "source": [
        "X_train, X_test,y_train, y_test = train_test_split(reviews_list, data_without_stopwords['Liked'].to_numpy(), test_size=0.33, random_state = 45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiDOuE9acMr7",
        "outputId": "01bfeb6d-6084-4df7-8cee-3993722a11ea"
      },
      "source": [
        "print(len(X_train),\n",
        "len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "670 670\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3DxyQY-b6aY"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "words_to_index = tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gChz28Akd2yR",
        "outputId": "4fe5b950-6fab-44b4-ca99-58add82c48ff"
      },
      "source": [
        "len(words_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1570"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKjJdOEIcX4L"
      },
      "source": [
        "def read_glove_vector(glove_vec):\n",
        "  with open(glove_vec, 'r', encoding='UTF-8') as f:\n",
        "    words = set()\n",
        "    word_to_vec_map = {}\n",
        "    for line in f:\n",
        "      w_line = line.split()\n",
        "      curr_word = w_line[0]\n",
        "      word_to_vec_map[curr_word] = np.array(w_line[1:], dtype=np.float64)\n",
        "  return word_to_vec_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ihfa3wkcnmo"
      },
      "source": [
        "word_to_vec_map = read_glove_vector('glove.6B.50d.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlZ9DaBGcrrg"
      },
      "source": [
        "maxLen = 150\n",
        "\n",
        "vocab_len = len(words_to_index) + 1\n",
        "embed_vector_len = word_to_vec_map['moon'].shape[0]\n",
        "\n",
        "emb_matrix = np.zeros((vocab_len, embed_vector_len))\n",
        "\n",
        "for word, index in words_to_index.items():\n",
        "  embedding_vector = word_to_vec_map.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    emb_matrix[index, :] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(input_dim=vocab_len, output_dim=embed_vector_len, input_length=maxLen, weights = [emb_matrix], trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPjnRUwo26OA",
        "outputId": "82dc60a2-5043-4728-9e5e-078d06a31949"
      },
      "source": [
        "len(emb_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhKTukc3cyho"
      },
      "source": [
        "def rating(input_shape):\n",
        "  X_indices = Input(input_shape)\n",
        "  embeddings = embedding_layer(X_indices)\n",
        "  X = LSTM(128, return_sequences=True)(embeddings)\n",
        "  X = Dense(1, activation='sigmoid')(X)\n",
        "  model = Model(inputs=X_indices, outputs=X)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DBgfmxDdTqY",
        "outputId": "06f38856-a421-45e2-d361-04c21d1858be"
      },
      "source": [
        "model = rating((maxLen,))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 150)]             0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 150, 50)           78550     \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 150, 128)          91648     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 150, 1)            129       \n",
            "=================================================================\n",
            "Total params: 170,327\n",
            "Trainable params: 91,777\n",
            "Non-trainable params: 78,550\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGUsvppAdWcI",
        "outputId": "31b737a7-c7dc-4a2f-b7f9-ea2b763ca0a0"
      },
      "source": [
        "X_train_indices = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_indices = pad_sequences(X_train_indices, maxlen=maxLen, padding='post')\n",
        "X_train_indices.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(670, 150)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPQRujyKdbGb"
      },
      "source": [
        "adam = keras.optimizers.Adam(learning_rate = 3e-4)\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh1D-uRkdfGr",
        "outputId": "871c61dd-6704-4af6-a9c4-ce9218ffb585"
      },
      "source": [
        "# callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', min_delta=0, patience=0, verbose=0,mode='auto', baseline=None, restore_best_weights=False)\n",
        "model.fit(X_train_indices, y_train, batch_size=64, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "11/11 [==============================] - 3s 246ms/step - loss: 0.3508 - accuracy: 0.8912\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 3s 246ms/step - loss: 0.3576 - accuracy: 0.8824\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.3759 - accuracy: 0.8748\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 3s 248ms/step - loss: 0.3324 - accuracy: 0.8982\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 3s 244ms/step - loss: 0.3250 - accuracy: 0.9016\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.3683 - accuracy: 0.8810\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.3207 - accuracy: 0.9040\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 3s 244ms/step - loss: 0.3148 - accuracy: 0.9061\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 3s 247ms/step - loss: 0.3054 - accuracy: 0.9105\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.3004 - accuracy: 0.9134\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.2963 - accuracy: 0.9150\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 3s 247ms/step - loss: 0.2932 - accuracy: 0.9161\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 3s 244ms/step - loss: 0.2901 - accuracy: 0.9177\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 3s 244ms/step - loss: 0.2895 - accuracy: 0.9178\n",
            "Epoch 15/30\n",
            "11/11 [==============================] - 3s 246ms/step - loss: 0.2891 - accuracy: 0.9179\n",
            "Epoch 16/30\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.2882 - accuracy: 0.9180\n",
            "Epoch 17/30\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.2887 - accuracy: 0.9178\n",
            "Epoch 18/30\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.2853 - accuracy: 0.9194\n",
            "Epoch 19/30\n",
            "11/11 [==============================] - 3s 242ms/step - loss: 0.2855 - accuracy: 0.9193\n",
            "Epoch 20/30\n",
            "11/11 [==============================] - 3s 241ms/step - loss: 0.2851 - accuracy: 0.9194\n",
            "Epoch 21/30\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.2838 - accuracy: 0.9194\n",
            "Epoch 22/30\n",
            "11/11 [==============================] - 3s 245ms/step - loss: 0.2848 - accuracy: 0.9194\n",
            "Epoch 23/30\n",
            "11/11 [==============================] - 3s 241ms/step - loss: 0.2846 - accuracy: 0.9194\n",
            "Epoch 24/30\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.2835 - accuracy: 0.9194\n",
            "Epoch 25/30\n",
            "11/11 [==============================] - 3s 241ms/step - loss: 0.2829 - accuracy: 0.9194\n",
            "Epoch 26/30\n",
            "11/11 [==============================] - 3s 243ms/step - loss: 0.2834 - accuracy: 0.9193\n",
            "Epoch 27/30\n",
            "11/11 [==============================] - 3s 244ms/step - loss: 0.2822 - accuracy: 0.9193\n",
            "Epoch 28/30\n",
            "11/11 [==============================] - 3s 244ms/step - loss: 0.2831 - accuracy: 0.9193\n",
            "Epoch 29/30\n",
            "11/11 [==============================] - 3s 244ms/step - loss: 0.2827 - accuracy: 0.9193\n",
            "Epoch 30/30\n",
            "11/11 [==============================] - 3s 242ms/step - loss: 0.2819 - accuracy: 0.9193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f37182bf110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hH9esvwxdgw_",
        "outputId": "5ce043e9-8575-4e43-9b39-afddecdabd06"
      },
      "source": [
        "X_test_indices = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
        "model.evaluate(X_test_indices, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11/11 [==============================] - 1s 44ms/step - loss: 0.7401 - accuracy: 0.7225\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7401497960090637, 0.7225050330162048]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrlHKqlMHTgo"
      },
      "source": [
        "model.save('mip.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MkT3EX6TMSJ6",
        "outputId": "05e74da5-7b03-472d-81df-d7794037df92"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"mip.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_05bb0566-b8d5-4bf6-8a64-933790e9801e\", \"mip.h5\", 1448088)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}